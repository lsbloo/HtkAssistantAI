2025-09-23 07:57:32,019 - INFO - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 07:58:33,883 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 07:59:39,002 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:00:21,546 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:05:52,178 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:06:24,602 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:06:56,482 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:07:38,402 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:08:27,538 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:09:07,755 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:12:09,738 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:17:37,841 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:17:40,402 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:18:07,225 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:18:08,850 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:25:11,545 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:25:13,881 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq'}
2025-09-23 08:25:13,881 - DEBUG - No user input provided.
2025-09-23 08:25:17,857 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq'}
2025-09-23 08:25:17,857 - DEBUG - No user input provided.
2025-09-23 08:26:13,409 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 08:26:14,128 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq'}
2025-09-23 08:26:14,160 - DEBUG - No user input provided.
2025-09-23 08:46:55,392 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:00:45,382 - DEBUG - Observer received data: {'user_input': 'pensando em ficar deitado', 'selected_model': 'Groq'}
2025-09-23 09:00:45,454 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 09:00:45,458 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 09:00:45,469 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 09:00:45,469 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 09:00:45,541 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are the user.'}, {'role': 'user', 'content': 'pensando em ficar deitado'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 09:00:45,564 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 09:00:45,912 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021E3FCA0130>
2025-09-23 09:00:45,912 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E3FAD9940> server_hostname='api.groq.com' timeout=None
2025-09-23 09:00:45,966 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021E3FC5BFA0>
2025-09-23 09:00:45,967 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 09:00:45,967 - DEBUG - send_request_headers.complete
2025-09-23 09:00:45,967 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 09:00:45,967 - DEBUG - send_request_body.complete
2025-09-23 09:00:45,967 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 09:00:51,508 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 12:00:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11979'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_01k5v755xfe1nvcz1ext03a298'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=p78yl0a4AcS6o2JL00xUEm5ujWv7acdgtJoB8RWEMHY-1758628850-1.0.1.1-dDFkJ_5ZLKPX82Jph1UPBFrRUZhyTMRY9VmbV5fzaoXr70pLxdH55VZGC1j2uPo7cClgWs2PH.fWq9.Li95eYPAZNMJ7Gb_QcdGhEYP6Z00; path=/; expires=Tue, 23-Sep-25 12:30:50 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9839e22bf977cb64-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 09:00:51,509 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 09:00:51,509 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 09:00:51,509 - DEBUG - receive_response_body.complete
2025-09-23 09:00:51,510 - DEBUG - response_closed.started
2025-09-23 09:00:51,510 - DEBUG - response_closed.complete
2025-09-23 09:00:51,510 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 09:00:55,428 - DEBUG - close.started
2025-09-23 09:00:55,431 - DEBUG - close.complete
2025-09-23 09:01:12,022 - DEBUG - Observer received data: {'user_input': 'me de uma dica do que fazer', 'selected_model': 'Groq'}
2025-09-23 09:01:12,023 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 09:01:12,023 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 09:01:12,033 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 09:01:12,033 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 09:01:12,044 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are the user.'}, {'role': 'user', 'content': 'me de uma dica do que fazer'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 09:01:12,045 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 09:01:12,094 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021E3FCA2AD0>
2025-09-23 09:01:12,094 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E3FAD9FC0> server_hostname='api.groq.com' timeout=None
2025-09-23 09:01:12,149 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021E3FCA2AA0>
2025-09-23 09:01:12,150 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 09:01:12,150 - DEBUG - send_request_headers.complete
2025-09-23 09:01:12,150 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 09:01:12,150 - DEBUG - send_request_body.complete
2025-09-23 09:01:12,150 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 09:01:13,836 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 12:01:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'998'), (b'x-ratelimit-remaining-tokens', b'11979'), (b'x-ratelimit-reset-requests', b'2m26.649999999s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_01k5v75zete1prszftc9pym8w0'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=n9zXHn3nlNABiV59uFr1a89PgdXvmoO53GoMD5mBsaw-1758628873-1.0.1.1-iR_E35J4601YfCTnxZbQMQfdNo3yXzwV2BVPUGmEXPrzqu5k4g.K_DZcwreTxkKENJahHr9ugXjSV_05iyonPsnIdS.eZnNPUSZA25BsEBE; path=/; expires=Tue, 23-Sep-25 12:31:13 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9839e2cf990b644b-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 09:01:13,837 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 09:01:13,837 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 09:01:13,837 - DEBUG - receive_response_body.complete
2025-09-23 09:01:13,837 - DEBUG - response_closed.started
2025-09-23 09:01:13,837 - DEBUG - response_closed.complete
2025-09-23 09:01:13,837 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 09:02:20,532 - DEBUG - close.started
2025-09-23 09:02:20,533 - DEBUG - close.complete
2025-09-23 09:04:37,086 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:05:26,615 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:05:48,470 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:07:29,159 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:08:02,719 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:09:15,143 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:09:37,038 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:12:09,238 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:13:02,318 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:13:31,598 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:13:51,518 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:14:19,614 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:14:37,334 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:15:14,542 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': True, 'image_generation': False}
2025-09-23 09:16:47,582 - DEBUG - Selected Model: Groq with Input Options: {'chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:16:47,583 - DEBUG - Input Options Values: ['chat', 'chat_with_roles']
2025-09-23 09:17:16,966 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:17:16,967 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:19:25,894 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:19:25,895 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:21:25,998 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:21:25,999 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:21:33,478 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:21:37,061 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles'}
2025-09-23 09:21:37,102 - DEBUG - No user input provided.
2025-09-23 09:21:52,182 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:21:53,190 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq', 'selected_option': 'simple_chat'}
2025-09-23 09:21:53,200 - DEBUG - No user input provided.
2025-09-23 09:24:41,382 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:24:41,383 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:24:43,398 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:24:50,453 - DEBUG - Observer received data: {'user_input': 'oii tudo bem', 'selected_model': 'Groq', 'selected_option': 'simple_chat'}
2025-09-23 09:24:50,507 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 09:24:50,508 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 09:24:50,519 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 09:24:50,519 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 09:24:50,530 - DEBUG - GroqClientFacade: chat called
2025-09-23 09:24:50,559 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'oii tudo bem'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 09:24:50,582 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 09:24:50,633 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A785ECC0A0>
2025-09-23 09:24:50,633 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A785D098C0> server_hostname='api.groq.com' timeout=None
2025-09-23 09:24:50,687 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A785ECC070>
2025-09-23 09:24:50,687 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 09:24:50,687 - DEBUG - send_request_headers.complete
2025-09-23 09:24:50,687 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 09:24:50,687 - DEBUG - send_request_body.complete
2025-09-23 09:24:50,687 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 09:24:51,175 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 12:24:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11979'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_01k5v8h8pte59bj82rjh5x1ak1'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UNSIyBqKANYVNKs.9B8D_t9itJlo5DowOzszmXkZA3s-1758630290-1.0.1.1-t2jd0oH0VjO6amHAkQnbbQwfkMpBi.snZDtCFH_gwK7nmyQOHJ8oBLb1ME0gu_UyuJ1pRkISCdILmbOLkPfbzaBVrvxZJaDiVWC3aBpztrU; path=/; expires=Tue, 23-Sep-25 12:54:50 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'983a0571387ee2bd-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 09:24:51,176 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 09:24:51,176 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 09:24:51,176 - DEBUG - receive_response_body.complete
2025-09-23 09:24:51,176 - DEBUG - response_closed.started
2025-09-23 09:24:51,176 - DEBUG - response_closed.complete
2025-09-23 09:24:51,177 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 09:25:20,992 - DEBUG - close.started
2025-09-23 09:25:20,992 - DEBUG - close.complete
2025-09-23 09:37:37,085 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:37:37,086 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:37:38,389 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:37:45,318 - DEBUG - Selected Role: system
2025-09-23 09:37:54,430 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:37:56,431 - DEBUG - Selected Role: assistant
2025-09-23 09:38:31,005 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:38:31,006 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:38:32,860 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:38:33,957 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:38:35,686 - DEBUG - Selected Role: assistant
2025-09-23 09:38:37,006 - DEBUG - Selected Role: user
2025-09-23 09:38:38,181 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:39:01,109 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:39:01,111 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:39:02,373 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:39:03,445 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:39:05,964 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:39:43,854 - DEBUG - Selected Role: system
2025-09-23 09:39:44,999 - DEBUG - Selected Role: assistant
2025-09-23 09:39:45,926 - DEBUG - Selected Role: user
2025-09-23 09:39:48,719 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:41:19,440 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:41:19,442 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:41:20,781 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:41:21,708 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:41:26,628 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:41:28,582 - DEBUG - Selected Role: user
2025-09-23 09:41:29,799 - DEBUG - Selected Role: system
2025-09-23 09:41:30,655 - DEBUG - Selected Role: assistant
2025-09-23 09:44:44,557 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:44:44,558 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:44:45,909 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:44:46,973 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:44:48,156 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:44:49,748 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:49:08,940 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:49:10,557 - DEBUG - Selected Role: user
2025-09-23 09:49:12,484 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:52:46,180 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:52:46,181 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:52:48,332 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:52:49,317 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:52:50,892 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:53:19,253 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 09:53:19,256 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 09:53:20,516 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:53:21,492 - DEBUG - Selected Model Option: simple_chat
2025-09-23 09:53:30,364 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 09:53:31,149 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:03:38,067 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 10:03:38,069 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 10:03:40,188 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:06:13,275 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 10:06:13,277 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 10:06:14,698 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:06:23,554 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': None}
2025-09-23 10:06:23,585 - DEBUG - No user input provided.
2025-09-23 10:09:36,843 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:09:38,965 - DEBUG - Selected Role: user
2025-09-23 10:09:43,666 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': 'user'}
2025-09-23 10:09:43,675 - DEBUG - No user input provided.
2025-09-23 10:09:50,293 - DEBUG - Selected Role: system
2025-09-23 10:09:51,395 - DEBUG - Observer received data: {'user_input': '', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': 'system'}
2025-09-23 10:09:51,405 - DEBUG - No user input provided.
2025-09-23 10:40:22,176 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:40:26,087 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:40:27,524 - DEBUG - Selected Role: user
2025-09-23 10:40:29,215 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:40:30,744 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:40:49,439 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 10:40:49,441 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 10:40:51,643 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:40:52,909 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:40:54,609 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:40:55,722 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:40:57,265 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:40:59,970 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:41:00,999 - DEBUG - Selected Role: user
2025-09-23 10:41:02,010 - DEBUG - Selected Model Option: simple_chat
2025-09-23 10:58:30,678 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 10:58:30,680 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 10:58:33,066 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:58:35,726 - DEBUG - Selected Role: system
2025-09-23 10:58:45,595 - DEBUG - Observer received data: {'user_input': 'qual sua role?', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': 'system'}
2025-09-23 10:58:45,650 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 10:58:45,652 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 10:58:45,663 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 10:58:45,663 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 10:59:35,678 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 10:59:35,680 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 10:59:36,898 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 10:59:38,678 - DEBUG - Selected Role: system
2025-09-23 10:59:44,871 - DEBUG - Observer received data: {'user_input': 'qual a sua role?', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': 'system'}
2025-09-23 10:59:44,928 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 10:59:44,930 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 10:59:44,940 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 10:59:44,940 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 10:59:44,950 - DEBUG - GroqClientFacade: chat_with_roles called with role: RoleType.SYSTEM
2025-09-23 10:59:44,983 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a system.'}, {'role': 'user', 'content': 'qual a sua role?'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 10:59:45,006 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 10:59:45,185 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226C32DC970>
2025-09-23 10:59:45,185 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000226C3111A40> server_hostname='api.groq.com' timeout=None
2025-09-23 10:59:45,238 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226C32DC940>
2025-09-23 10:59:45,239 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 10:59:45,239 - DEBUG - send_request_headers.complete
2025-09-23 10:59:45,239 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 10:59:45,239 - DEBUG - send_request_body.complete
2025-09-23 10:59:45,239 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 10:59:46,299 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 13:59:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11981'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_01k5vdz1mneqnap69eqk225gk0'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gyMweFTn7hi6ixvB_aMuwviOKg.SDPGK7Wpe7bgV8Y4-1758635985-1.0.1.1-aENl._1Kgoj58tBBNrA.sQbLPUyWWGPFggPVfTjGajBh46WDgmNZklJz83XfYtMdkl9LzQGehXAjQQ7ZcgyZMeu7NFuLEO5VCKF2WdgHYxk; path=/; expires=Tue, 23-Sep-25 14:29:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'983a90770cf0e016-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 10:59:46,300 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 10:59:46,300 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 10:59:46,300 - DEBUG - receive_response_body.complete
2025-09-23 10:59:46,300 - DEBUG - response_closed.started
2025-09-23 10:59:46,300 - DEBUG - response_closed.complete
2025-09-23 10:59:46,300 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 11:00:08,065 - DEBUG - close.started
2025-09-23 11:00:08,065 - DEBUG - close.complete
2025-09-23 11:00:20,352 - DEBUG - Observer received data: {'user_input': 'nossa conversa foi iniciada e eu lhe dei um papel, qual foi?', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': 'system'}
2025-09-23 11:00:20,352 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 11:00:20,353 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 11:00:20,363 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 11:00:20,364 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 11:00:20,374 - DEBUG - GroqClientFacade: chat_with_roles called with role: RoleType.SYSTEM
2025-09-23 11:00:20,375 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a system.'}, {'role': 'user', 'content': 'nossa conversa foi iniciada e eu lhe dei um papel, qual foi?'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 11:00:20,376 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 11:00:20,424 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226C3320580>
2025-09-23 11:00:20,425 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000226C3111DC0> server_hostname='api.groq.com' timeout=None
2025-09-23 11:00:20,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226C3320550>
2025-09-23 11:00:20,481 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 11:00:20,481 - DEBUG - send_request_headers.complete
2025-09-23 11:00:20,481 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 11:00:20,481 - DEBUG - send_request_body.complete
2025-09-23 11:00:20,481 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 11:00:20,974 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 14:00:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'998'), (b'x-ratelimit-remaining-tokens', b'11970'), (b'x-ratelimit-reset-requests', b'2m17.580999999s'), (b'x-ratelimit-reset-tokens', b'150ms'), (b'x-request-id', b'req_01k5ve041deqpbcvvacv9t08zb'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=shrwpUrTrp_348_1_IE5Ca2TN1i3gxdoi3e32UUygUg-1758636020-1.0.1.1-xHPLSLmTr1ke2h6caLXKJ4nH_2DEuKimypZcOcVFPt4vx8wxzEv9HPrk.2ptvbUsN.UqWFqMHn.6HesQVctkjwJoHPQjYj7pEOyzkf0G6rE; path=/; expires=Tue, 23-Sep-25 14:30:20 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'983a915349e9df4e-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 11:00:20,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 11:00:20,975 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 11:00:20,975 - DEBUG - receive_response_body.complete
2025-09-23 11:00:20,975 - DEBUG - response_closed.started
2025-09-23 11:00:20,975 - DEBUG - response_closed.complete
2025-09-23 11:00:20,976 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 11:01:07,263 - DEBUG - Observer received data: {'user_input': 'me explique como funciona o clico de vida de uma activity android de forma resumida', 'selected_model': 'Groq', 'selected_option': 'chat_with_roles', 'option_role_choice': 'system'}
2025-09-23 11:01:07,264 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 11:01:07,264 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 11:01:07,276 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 11:01:07,276 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 11:01:07,286 - DEBUG - GroqClientFacade: chat_with_roles called with role: RoleType.SYSTEM
2025-09-23 11:01:07,287 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a system.'}, {'role': 'user', 'content': 'me explique como funciona o clico de vida de uma activity android de forma resumida'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 11:01:07,288 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 11:01:07,336 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226C3323370>
2025-09-23 11:01:07,336 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000226C3111CC0> server_hostname='api.groq.com' timeout=None
2025-09-23 11:01:07,393 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226C3323340>
2025-09-23 11:01:07,393 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 11:01:07,393 - DEBUG - send_request_headers.complete
2025-09-23 11:01:07,394 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 11:01:07,394 - DEBUG - send_request_body.complete
2025-09-23 11:01:07,394 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 11:01:08,794 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 14:01:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'997'), (b'x-ratelimit-remaining-tokens', b'11965'), (b'x-ratelimit-reset-requests', b'3m32.287999999s'), (b'x-ratelimit-reset-tokens', b'175ms'), (b'x-request-id', b'req_01k5ve1hvbf0krj3wtyrkaqpwh'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rgBhm1Ig4mkiRMu4Z_mMq18MiWQa3ayZmY_K4cbPTbU-1758636067-1.0.1.1-7i0iB7gPQKPQbJ6huYn7aXhYtJVi0mstbm9YBSjnMbN2Fr4hG9lnGvjdVqBmPpISj8oYj7pYyTjnbIshbaUbMNwyRfFielVcozN7eAVcyCg; path=/; expires=Tue, 23-Sep-25 14:31:07 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'983a92787dcf64b4-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 11:01:08,795 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 11:01:08,795 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 11:01:08,795 - DEBUG - receive_response_body.complete
2025-09-23 11:01:08,795 - DEBUG - response_closed.started
2025-09-23 11:01:08,795 - DEBUG - response_closed.complete
2025-09-23 11:01:08,795 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 11:01:36,524 - DEBUG - Selected Model Option: simple_chat
2025-09-23 14:42:19,659 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 14:42:19,660 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 14:42:25,395 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 14:42:29,747 - DEBUG - Selected Model Option: simple_chat
2025-09-23 14:42:31,987 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 14:42:33,787 - DEBUG - Selected Model Option: simple_chat
2025-09-23 14:48:17,955 - DEBUG - Selected Model Option: chat_with_roles
2025-09-23 14:48:20,076 - DEBUG - Selected Role: system
2025-09-23 14:48:22,245 - DEBUG - Selected Role: user
2025-09-23 14:48:23,276 - DEBUG - Selected Role: assistant
2025-09-23 14:48:24,412 - DEBUG - Selected Model Option: simple_chat
2025-09-23 14:48:25,802 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-23 14:48:25,803 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-23 20:53:05,701 - DEBUG - Selected Model Option: simple_chat
2025-09-23 20:53:11,741 - DEBUG - Observer received data: {'user_input': 'sei la to meio pra baixo hoje', 'selected_model': 'Groq', 'selected_option': 'simple_chat', 'option_role_choice': 'assistant'}
2025-09-23 20:53:11,999 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 20:53:12,049 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 20:53:12,072 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 20:53:12,072 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 20:53:12,083 - DEBUG - GroqClientFacade: chat called
2025-09-23 20:53:12,301 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'sei la to meio pra baixo hoje'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 20:53:12,335 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 20:53:12,809 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016B67EF8A60>
2025-09-23 20:53:12,809 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016B67D45BC0> server_hostname='api.groq.com' timeout=None
2025-09-23 20:53:12,881 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016B67EF8A30>
2025-09-23 20:53:12,881 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 20:53:12,882 - DEBUG - send_request_headers.complete
2025-09-23 20:53:12,882 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 20:53:12,882 - DEBUG - send_request_body.complete
2025-09-23 20:53:12,882 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 20:53:13,917 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 23:53:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11975'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'125ms'), (b'x-request-id', b'req_01k5wfxpb3fx9bde5sdcr9nh73'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1R5r4N27cf9Zn3Zh53ZpQLu3Othf.6Fqp8TFkXyxhok-1758671592-1.0.1.1-MzY_EyAeMUO4DLl6vf3MKAaMXODn.XdhGQs3D36jF937mTowWFLbidp5gP7xSJXiw_DzszsajnAB0Rq3InDsehG1E9NmF6TG.P8Ha7jKB48; path=/; expires=Wed, 24-Sep-25 00:23:12 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'983df5c859e4e2bf-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 20:53:13,918 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 20:53:13,919 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 20:53:13,921 - DEBUG - receive_response_body.complete
2025-09-23 20:53:13,922 - DEBUG - response_closed.started
2025-09-23 20:53:13,922 - DEBUG - response_closed.complete
2025-09-23 20:53:13,922 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 20:53:53,501 - DEBUG - Observer received data: {'user_input': 'os impostos me deixa triste, parece que so trabalho para pagar dividas. Alias meu nome é osvaldo', 'selected_model': 'Groq', 'selected_option': 'simple_chat', 'option_role_choice': 'assistant'}
2025-09-23 20:53:53,502 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 20:53:53,502 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 20:53:53,512 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-23 20:53:53,513 - DEBUG - load_verify_locations cafile='C:\\Users\\osval\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\certifi\\cacert.pem'
2025-09-23 20:53:53,523 - DEBUG - GroqClientFacade: chat called
2025-09-23 20:53:53,524 - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'os impostos me deixa triste, parece que so trabalho para pagar dividas. Alias meu nome é osvaldo'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 1000, 'n': 1, 'stop': None, 'stream': False, 'temperature': 0.7}}
2025-09-23 20:53:53,525 - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None
2025-09-23 20:53:53,576 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016B67F4C790>
2025-09-23 20:53:53,576 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016B67E3A540> server_hostname='api.groq.com' timeout=None
2025-09-23 20:53:53,631 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016B67F4C760>
2025-09-23 20:53:53,631 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-23 20:53:53,631 - DEBUG - send_request_headers.complete
2025-09-23 20:53:53,631 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-23 20:53:53,631 - DEBUG - send_request_body.complete
2025-09-23 20:53:53,631 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-23 20:53:55,251 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Sep 2025 23:53:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bra'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'998'), (b'x-ratelimit-remaining-tokens', b'11958'), (b'x-ratelimit-reset-requests', b'2m12.07s'), (b'x-ratelimit-reset-tokens', b'210ms'), (b'x-request-id', b'req_01k5wfyy47e9sbnevqv6czrpeg'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fBl151t1EFRuEMghv_.5tTyea0asT0N9DQ38Ji658qY-1758671634-1.0.1.1-L7dklhF.D9E2el3My.N6GPia8tZj9pdNVVdteG35t5U1XuwgQ79.AouSDN0_vvRnOxw7XjsKbOUw.aO8hg4sZZkvNPzBkY8.MhcFHzSbY5A; path=/; expires=Wed, 24-Sep-25 00:23:54 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'983df6c70e11cadb-GIG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-23 20:53:55,251 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-23 20:53:55,251 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-23 20:53:55,252 - DEBUG - receive_response_body.complete
2025-09-23 20:53:55,252 - DEBUG - response_closed.started
2025-09-23 20:53:55,252 - DEBUG - response_closed.complete
2025-09-23 20:53:55,252 - DEBUG - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "200 OK"
2025-09-23 20:53:58,464 - DEBUG - close.started
2025-09-23 20:53:58,464 - DEBUG - close.complete
2025-09-25 16:44:49,759 - DEBUG - close.started
2025-09-25 16:44:49,760 - DEBUG - close.complete
2025-09-25 17:02:04,541 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-25 17:02:04,542 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
2025-09-25 17:02:06,764 - DEBUG - Selected Model Option: chat_with_roles
2025-09-25 17:06:16,255 - DEBUG - Absolute path for resource no-face.ico: D:\Projetos Python\HtkAssistantAI\HtkAssistantAI\res\no-face.ico
2025-09-25 17:19:26,372 - DEBUG - Selected Model: Groq with Input Options: {'simple_chat': True, 'chat_with_roles': True, 'response': False, 'image_generation': False}
2025-09-25 17:19:26,373 - DEBUG - Input Options Values: ['simple_chat', 'chat_with_roles']
